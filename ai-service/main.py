from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from PIL import Image
import io
import numpy as np
import cv2
import torch
from sentence_transformers import SentenceTransformer
import faiss
from typing import List, Dict, Any
import os
from datetime import datetime

app = FastAPI(title="KG Annotation AI Service", version="0.1.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒ
yolo_model = None
sentence_model = None
vector_index = None

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    global yolo_model, sentence_model, vector_index
    
    print("ğŸš€ Loading AI models...")
    
    # YOLOXãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        from ultralytics import YOLO
        yolo_model = YOLO('yolov8n.pt')  # è»½é‡ç‰ˆã‹ã‚‰é–‹å§‹
        print("âœ… YOLO model loaded")
    except Exception as e:
        print(f"âŒ Failed to load YOLO model: {e}")
    
    # Sentence Transformersãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… Sentence Transformer model loaded")
    except Exception as e:
        print(f"âŒ Failed to load Sentence Transformer: {e}")
    
    # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸåŒ–
    vector_index = faiss.IndexFlatIP(384)  # all-MiniLM-L6-v2ã®æ¬¡å…ƒæ•°
    print("âœ… Vector index initialized")

@app.get("/")
async def root():
    return {
        "message": "ğŸ KG Annotation AI Service",
        "status": "healthy",
        "version": "0.1.0",
        "models_loaded": {
            "yolo": yolo_model is not None,
            "sentence_transformer": sentence_model is not None,
            "vector_index": vector_index is not None
        }
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models_status": {
            "yolo": "loaded" if yolo_model else "not_loaded",
            "sentence_transformer": "loaded" if sentence_model else "not_loaded",
            "vector_index": "initialized" if vector_index else "not_initialized"
        }
    }

@app.post("/detect")
async def detect_objects(image: UploadFile = File(...)):
    """YOLOXç‰©ä½“æ¤œå‡ºAPI"""
    if yolo_model is None:
        raise HTTPException(status_code=503, detail="YOLO model not loaded")
    
    try:
        # ç”»åƒèª­ã¿è¾¼ã¿
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes))
        
        # RGBå¤‰æ›
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # YOLOæ¨è«–
        results = yolo_model(pil_image)
        
        # æ¤œå‡ºçµæœã‚’å‡¦ç†
        detections = []
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    conf = box.conf[0].item()
                    cls = int(box.cls[0].item())
                    class_name = yolo_model.names[cls]
                    
                    detections.append({
                        "id": i,
                        "class_name": class_name,
                        "confidence": round(conf, 3),
                        "bbox": {
                            "x1": round(x1, 2),
                            "y1": round(y1, 2),
                            "x2": round(x2, 2),
                            "y2": round(y2, 2)
                        }
                    })
        
        return {
            "success": True,
            "image_info": {
                "filename": image.filename,
                "size": pil_image.size,
                "format": pil_image.format
            },
            "detections": detections,
            "total_objects": len(detections)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Detection failed: {str(e)}")

@app.post("/vectorize")
async def vectorize_text(texts: List[str]):
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–API"""
    if sentence_model is None:
        raise HTTPException(status_code=503, detail="Sentence Transformer model not loaded")
    
    try:
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embeddings = sentence_model.encode(texts, convert_to_tensor=False)
        
        return {
            "success": True,
            "vectors": embeddings.tolist(),
            "dimension": embeddings.shape[1],
            "total_texts": len(texts)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Vectorization failed: {str(e)}")

@app.post("/search_similar")
async def search_similar_images(query_vector: List[float], top_k: int = 5):
    """ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ¤œç´¢API"""
    if vector_index is None:
        raise HTTPException(status_code=503, detail="Vector index not initialized")
    
    try:
        query_array = np.array([query_vector], dtype=np.float32)
        
        # æ¤œç´¢å®Ÿè¡Œ
        scores, indices = vector_index.search(query_array, top_k)
        
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx != -1:  # æœ‰åŠ¹ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                results.append({
                    "rank": i + 1,
                    "index": int(idx),
                    "similarity_score": float(score)
                })
        
        return {
            "success": True,
            "query_dimension": len(query_vector),
            "results": results,
            "total_found": len(results)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")

if __name__ == "__main__":
    print("ğŸ KG Annotation AI Service starting...")
    uvicorn.run(app, host="0.0.0.0", port=8000)